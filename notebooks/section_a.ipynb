{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e915e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\nsys.path.insert(0, \"../src\")\n\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "\n",
    "from boo_nn import NeuralNetwork, train_neural_network, evaluate_neural_network\n",
    "from autoencoder_gmm import AutoencoderGMM\n",
    "from probabilistic_model import ProbabilisticModel\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed275974",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_labels = {\n",
    "    'hda': 0,\n",
    "    'lda': 1,\n",
    "    'liquid': 2,\n",
    "    'ice': 2\n",
    "}\n",
    "\n",
    "def load_data(model, feat='all', size=16, states=['hda', 'lda']):\n",
    "    ''' Method for efficiently loading environments for a given number of neighbors. '''\n",
    "    desc_dir = '..'\n",
    "    descs = []\n",
    "    labels = []\n",
    "    for state in states:\n",
    "        if feat == 'stein':\n",
    "            stein = np.load(f'{desc_dir}/data/descriptors/neigh_{size}/{model}_{state}_stein.npy')\n",
    "            descs.append(stein)\n",
    "            for _ in range(stein.shape[0]):\n",
    "                labels.append(state_labels[state])\n",
    "        elif feat == 'acsf':\n",
    "            acsf = np.load(f'{desc_dir}/data/descriptors/neigh_{size}/{model}_{state}_acsf.npy')\n",
    "            descs.append(acsf)\n",
    "            for _ in range(acsf.shape[0]):\n",
    "                labels.append(state_labels[state])\n",
    "        elif feat == 'all':\n",
    "            acsf = np.load(f'{desc_dir}/data/descriptors/neigh_{size}/{model}_{state}_acsf.npy')\n",
    "            stein = np.load(f'{desc_dir}/data/descriptors/neigh_{size}/{model}_{state}_stein.npy')\n",
    "            desc = np.hstack((acsf, stein))\n",
    "            descs.append(desc)\n",
    "            for _ in range(desc.shape[0]):\n",
    "                labels.append(state_labels[state])\n",
    "    desc = np.vstack(descs)\n",
    "    labels = np.array(labels)\n",
    "    return desc, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f8b251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify water model (either 'scan' or 'mbpol').\n",
    "MODEL = 'mbpol'\n",
    "\n",
    "# Save probabilites for outlier detection analysis.\n",
    "probabilities = {\n",
    "    'boo-nn': {'hda': [], 'lda': []},\n",
    "    'pointnet': {'hda': [], 'lda': []},\n",
    "    'ae-gmm': {'hda': [], 'lda': []},\n",
    "    'ours': {'hda': [], 'lda': []},\n",
    "}\n",
    "ice_probabilities = {\n",
    "    'boo-nn': {'hda': [], 'lda': []},\n",
    "    'pointnet': {'hda': [], 'lda': []},\n",
    "    'ae-gmm': {'hda': [], 'lda': []},\n",
    "    'ours': {'hda': [], 'lda': []},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc9824c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1 / 5.\n",
      "Evaluating fold 2 / 5.\n",
      "Evaluating fold 3 / 5.\n",
      "Evaluating fold 4 / 5.\n",
      "Evaluating fold 5 / 5.\n",
      "HDA Precision: 0.997 +/- 0.001\n",
      "LDA Precision: 0.997 +/- 0.002\n",
      "HDA Recall: 0.997 +/- 0.002\n",
      "LDA Recall: 0.997 +/- 0.001\n",
      "Accuracy: 0.997 +/- 0.001\n"
     ]
    }
   ],
   "source": [
    "# Prepare datasets for BOO-NN.\n",
    "X, y = load_data(model=MODEL, feat='stein')\n",
    "hda_idx = np.argwhere(y == 0).reshape(-1)\n",
    "lda_idx = np.argwhere(y == 1).reshape(-1)\n",
    "\n",
    "# Convert labels to one-hot encoding.\n",
    "y_ohe = np.zeros((y.shape[0], 2), dtype=np.int32)\n",
    "for y_idx, y_class in enumerate(y):\n",
    "    y_ohe[y_idx,y_class] = 1\n",
    "y = y_ohe\n",
    "\n",
    "# Assess classification accuracy for BOO-NN.\n",
    "metrics = {\n",
    "    'hda_precisions': [],\n",
    "    'lda_precisions': [],\n",
    "    'hda_recalls': [],\n",
    "    'lda_recalls': [],\n",
    "    'accuracies': []\n",
    "}\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "for idx, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    print(f'Evaluating fold {idx + 1} / 5.')\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    model = NeuralNetwork(in_dim=X_train.shape[1], n_classes=2)\n",
    "    train_neural_network(model, X_train, y_train)\n",
    "    _, probs = evaluate_neural_network(model, X_test, prob=True)\n",
    "\n",
    "    # Save probabilities for true configurations for subsequent analysis.\n",
    "    lda_idx = np.argwhere(np.argmax(y_test, axis=1) == 1).reshape(-1) \n",
    "    hda_idx = np.argwhere(np.argmax(y_test, axis=1) == 0).reshape(-1) \n",
    "    lda_probs = probs[lda_idx, 1]\n",
    "    hda_probs = probs[hda_idx, 0]\n",
    "    probabilities['boo-nn']['lda'].append(lda_probs)\n",
    "    probabilities['boo-nn']['hda'].append(hda_probs)\n",
    "    y_pred = np.argmax(probs, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Save performance metrics.\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    metrics['hda_precisions'].append(conf_mat[0,0] / (conf_mat[1,0] + conf_mat[0,0]))\n",
    "    metrics['lda_precisions'].append(conf_mat[1,1] / (conf_mat[0,1] + conf_mat[1,1]))\n",
    "    metrics['hda_recalls'].append(conf_mat[0,0] / (conf_mat[0,1] + conf_mat[0,0]))\n",
    "    metrics['lda_recalls'].append(conf_mat[1,1] / (conf_mat[1,0] + conf_mat[1,1]))\n",
    "    metrics['accuracies'].append((conf_mat[0,0] + conf_mat[1,1]) / np.sum(conf_mat, axis=(0,1)))\n",
    "\n",
    "# Report accuracy metrics.\n",
    "print(f'HDA Precision: {np.mean(metrics[\"hda_precisions\"]):.3f} +/- {np.std(metrics[\"hda_precisions\"]):.3f}')\n",
    "print(f'LDA Precision: {np.mean(metrics[\"lda_precisions\"]):.3f} +/- {np.std(metrics[\"lda_precisions\"]):.3f}')\n",
    "print(f'HDA Recall: {np.mean(metrics[\"hda_recalls\"]):.3f} +/- {np.std(metrics[\"hda_recalls\"]):.3f}')\n",
    "print(f'LDA Recall: {np.mean(metrics[\"lda_recalls\"]):.3f} +/- {np.std(metrics[\"lda_recalls\"]):.3f}')\n",
    "print(f'Accuracy: {np.mean(metrics[\"accuracies\"]):.3f} +/- {np.std(metrics[\"accuracies\"]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a221a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain BOO-NN model on all HDA, LDA, and liquid configurations.\n",
    "model = NeuralNetwork(in_dim=X.shape[1], n_classes=2)\n",
    "train_neural_network(model, X, y)\n",
    "\n",
    "# Evaluate trained BOO-NN when extrapolating to hexagonal ice structures.\n",
    "X_ice = np.load(f'../data/descriptors/neigh_16/{MODEL}_ice_stein.npy')\n",
    "y_ice, prob_ice = evaluate_neural_network(model, X_ice, prob=True)\n",
    "ice_probabilities['boo-nn']['hda'] = prob_ice[:,0]\n",
    "ice_probabilities['boo-nn']['lda'] = prob_ice[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3fedff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PointNet data.\n",
    "probabilities['pointnet']['hda'] = np.load(f'./data/{MODEL}_pointnet_hda_prob.npy')\n",
    "probabilities['pointnet']['lda'] = np.load(f'./data/{MODEL}_pointnet_lda_prob.npy')\n",
    "ice_probabilities['pointnet']['hda'] = np.load(f'./data/{MODEL}_pointnet_ice_hda_prob.npy')\n",
    "ice_probabilities['pointnet']['lda'] = np.load(f'./data/{MODEL}_pointnet_ice_lda_prob.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ececddcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1 / 5.\n",
      "Epoch 1 | Train loss = 0.00565787 | Val loss =  0.00556715 | Rate = 0.001000\n",
      "Epoch 2 | Train loss = 0.00536808 | Val loss =  0.00555717 | Rate = 0.001000\n",
      "Epoch 3 | Train loss = 0.00535735 | Val loss =  0.00553684 | Rate = 0.001000\n",
      "Epoch 4 | Train loss = 0.00533838 | Val loss =  0.00552814 | Rate = 0.001000\n",
      "Epoch 5 | Train loss = 0.00531869 | Val loss =  0.00550216 | Rate = 0.001000\n",
      "Epoch 6 | Train loss = 0.00529177 | Val loss =  0.00547560 | Rate = 0.001000\n",
      "Epoch 7 | Train loss = 0.00526432 | Val loss =  0.00545780 | Rate = 0.001000\n",
      "Epoch 8 | Train loss = 0.00523388 | Val loss =  0.00541774 | Rate = 0.001000\n",
      "Epoch 9 | Train loss = 0.00521878 | Val loss =  0.00541301 | Rate = 0.001000\n",
      "Epoch 10 | Train loss = 0.00520549 | Val loss =  0.00538573 | Rate = 0.001000\n",
      "Epoch 11 | Train loss = 0.00519552 | Val loss =  0.00538071 | Rate = 0.001000\n",
      "Epoch 12 | Train loss = 0.00518989 | Val loss =  0.00537873 | Rate = 0.001000\n",
      "Epoch 13 | Train loss = 0.00518399 | Val loss =  0.00536916 | Rate = 0.001000\n",
      "Epoch 14 | Train loss = 0.00517368 | Val loss =  0.00536225 | Rate = 0.001000\n",
      "Epoch 15 | Train loss = 0.00516793 | Val loss =  0.00535949 | Rate = 0.001000\n",
      "Epoch 16 | Train loss = 0.00516660 | Val loss =  0.00535929 | Rate = 0.001000\n",
      "Epoch 17 | Train loss = 0.00516270 | Val loss =  0.00535129 | Rate = 0.001000\n",
      "Epoch 18 | Train loss = 0.00516499 | Val loss =  0.00534262 | Rate = 0.001000\n",
      "Epoch 19 | Train loss = 0.00515542 | Val loss =  0.00536270 | Rate = 0.001000\n",
      "Epoch 20 | Train loss = 0.00515619 | Val loss =  0.00533651 | Rate = 0.001000\n",
      "Evaluating fold 2 / 5.\n",
      "Epoch 1 | Train loss = 0.00559451 | Val loss =  0.00555413 | Rate = 0.001000\n",
      "Epoch 2 | Train loss = 0.00536642 | Val loss =  0.00553235 | Rate = 0.001000\n",
      "Epoch 3 | Train loss = 0.00535162 | Val loss =  0.00553184 | Rate = 0.001000\n",
      "Epoch 4 | Train loss = 0.00534190 | Val loss =  0.00549691 | Rate = 0.001000\n",
      "Epoch 5 | Train loss = 0.00532309 | Val loss =  0.00548160 | Rate = 0.001000\n",
      "Epoch 6 | Train loss = 0.00529431 | Val loss =  0.00544813 | Rate = 0.001000\n",
      "Epoch 7 | Train loss = 0.00527008 | Val loss =  0.00540853 | Rate = 0.001000\n",
      "Epoch 8 | Train loss = 0.00523944 | Val loss =  0.00538868 | Rate = 0.001000\n",
      "Epoch 9 | Train loss = 0.00521814 | Val loss =  0.00536620 | Rate = 0.001000\n",
      "Epoch 10 | Train loss = 0.00520420 | Val loss =  0.00535077 | Rate = 0.001000\n",
      "Epoch 11 | Train loss = 0.00519219 | Val loss =  0.00535237 | Rate = 0.001000\n",
      "Epoch 12 | Train loss = 0.00518146 | Val loss =  0.00534854 | Rate = 0.001000\n",
      "Epoch 13 | Train loss = 0.00517511 | Val loss =  0.00534936 | Rate = 0.001000\n",
      "Epoch 14 | Train loss = 0.00516729 | Val loss =  0.00531698 | Rate = 0.001000\n",
      "Epoch 15 | Train loss = 0.00516346 | Val loss =  0.00532383 | Rate = 0.001000\n",
      "Epoch 16 | Train loss = 0.00515828 | Val loss =  0.00532089 | Rate = 0.001000\n",
      "Epoch 17 | Train loss = 0.00515865 | Val loss =  0.00531101 | Rate = 0.001000\n",
      "Epoch 18 | Train loss = 0.00514980 | Val loss =  0.00532076 | Rate = 0.001000\n",
      "Epoch 19 | Train loss = 0.00514899 | Val loss =  0.00531289 | Rate = 0.001000\n",
      "Epoch 20 | Train loss = 0.00514183 | Val loss =  0.00532481 | Rate = 0.001000\n",
      "Evaluating fold 3 / 5.\n",
      "Epoch 1 | Train loss = 0.00560717 | Val loss =  0.00561496 | Rate = 0.001000\n",
      "Epoch 2 | Train loss = 0.00538134 | Val loss =  0.00559440 | Rate = 0.001000\n",
      "Epoch 3 | Train loss = 0.00534959 | Val loss =  0.00555826 | Rate = 0.001000\n",
      "Epoch 4 | Train loss = 0.00532409 | Val loss =  0.00553879 | Rate = 0.001000\n",
      "Epoch 5 | Train loss = 0.00529580 | Val loss =  0.00552894 | Rate = 0.001000\n",
      "Epoch 6 | Train loss = 0.00526297 | Val loss =  0.00548054 | Rate = 0.001000\n",
      "Epoch 7 | Train loss = 0.00523493 | Val loss =  0.00546140 | Rate = 0.001000\n",
      "Epoch 8 | Train loss = 0.00520929 | Val loss =  0.00546278 | Rate = 0.001000\n",
      "Epoch 9 | Train loss = 0.00519813 | Val loss =  0.00543723 | Rate = 0.001000\n",
      "Epoch 10 | Train loss = 0.00518570 | Val loss =  0.00543388 | Rate = 0.001000\n",
      "Epoch 11 | Train loss = 0.00517688 | Val loss =  0.00542736 | Rate = 0.001000\n",
      "Epoch 12 | Train loss = 0.00517097 | Val loss =  0.00541846 | Rate = 0.001000\n",
      "Epoch 13 | Train loss = 0.00516219 | Val loss =  0.00541250 | Rate = 0.001000\n",
      "Epoch 14 | Train loss = 0.00515917 | Val loss =  0.00541157 | Rate = 0.001000\n",
      "Epoch 15 | Train loss = 0.00515553 | Val loss =  0.00541382 | Rate = 0.001000\n",
      "Epoch 16 | Train loss = 0.00515221 | Val loss =  0.00541960 | Rate = 0.001000\n",
      "Epoch 17 | Train loss = 0.00514829 | Val loss =  0.00538877 | Rate = 0.001000\n",
      "Epoch 18 | Train loss = 0.00514574 | Val loss =  0.00540483 | Rate = 0.001000\n",
      "Epoch 19 | Train loss = 0.00514126 | Val loss =  0.00539872 | Rate = 0.001000\n",
      "Epoch 20 | Train loss = 0.00513739 | Val loss =  0.00539838 | Rate = 0.001000\n",
      "Evaluating fold 4 / 5.\n",
      "Epoch 1 | Train loss = 0.00566779 | Val loss =  0.00561049 | Rate = 0.001000\n",
      "Epoch 2 | Train loss = 0.00537093 | Val loss =  0.00557227 | Rate = 0.001000\n",
      "Epoch 3 | Train loss = 0.00535227 | Val loss =  0.00555488 | Rate = 0.001000\n",
      "Epoch 4 | Train loss = 0.00533446 | Val loss =  0.00553684 | Rate = 0.001000\n",
      "Epoch 5 | Train loss = 0.00532098 | Val loss =  0.00551758 | Rate = 0.001000\n",
      "Epoch 6 | Train loss = 0.00528647 | Val loss =  0.00548070 | Rate = 0.001000\n",
      "Epoch 7 | Train loss = 0.00525855 | Val loss =  0.00546974 | Rate = 0.001000\n",
      "Epoch 8 | Train loss = 0.00523343 | Val loss =  0.00544065 | Rate = 0.001000\n",
      "Epoch 9 | Train loss = 0.00520920 | Val loss =  0.00540433 | Rate = 0.001000\n",
      "Epoch 10 | Train loss = 0.00519355 | Val loss =  0.00538703 | Rate = 0.001000\n",
      "Epoch 11 | Train loss = 0.00518427 | Val loss =  0.00538742 | Rate = 0.001000\n",
      "Epoch 12 | Train loss = 0.00517071 | Val loss =  0.00538809 | Rate = 0.001000\n",
      "Epoch 13 | Train loss = 0.00516813 | Val loss =  0.00538972 | Rate = 0.001000\n",
      "Epoch 14 | Train loss = 0.00515972 | Val loss =  0.00537277 | Rate = 0.001000\n",
      "Epoch 15 | Train loss = 0.00515633 | Val loss =  0.00537011 | Rate = 0.001000\n",
      "Epoch 16 | Train loss = 0.00515532 | Val loss =  0.00537613 | Rate = 0.001000\n",
      "Epoch 17 | Train loss = 0.00515242 | Val loss =  0.00539048 | Rate = 0.001000\n",
      "Epoch 18 | Train loss = 0.00514465 | Val loss =  0.00535244 | Rate = 0.001000\n",
      "Epoch 19 | Train loss = 0.00514275 | Val loss =  0.00535411 | Rate = 0.001000\n",
      "Epoch 20 | Train loss = 0.00513965 | Val loss =  0.00537787 | Rate = 0.001000\n",
      "Evaluating fold 5 / 5.\n",
      "Epoch 1 | Train loss = 0.00560701 | Val loss =  0.00552897 | Rate = 0.001000\n",
      "Epoch 2 | Train loss = 0.00536629 | Val loss =  0.00550346 | Rate = 0.001000\n",
      "Epoch 3 | Train loss = 0.00534085 | Val loss =  0.00546741 | Rate = 0.001000\n",
      "Epoch 4 | Train loss = 0.00532902 | Val loss =  0.00546087 | Rate = 0.001000\n",
      "Epoch 5 | Train loss = 0.00529882 | Val loss =  0.00542510 | Rate = 0.001000\n",
      "Epoch 6 | Train loss = 0.00526333 | Val loss =  0.00537965 | Rate = 0.001000\n",
      "Epoch 7 | Train loss = 0.00523762 | Val loss =  0.00536410 | Rate = 0.001000\n",
      "Epoch 8 | Train loss = 0.00521724 | Val loss =  0.00533236 | Rate = 0.001000\n",
      "Epoch 9 | Train loss = 0.00519976 | Val loss =  0.00534578 | Rate = 0.001000\n",
      "Epoch 10 | Train loss = 0.00518597 | Val loss =  0.00532056 | Rate = 0.001000\n",
      "Epoch 11 | Train loss = 0.00518014 | Val loss =  0.00531805 | Rate = 0.001000\n",
      "Epoch 12 | Train loss = 0.00517675 | Val loss =  0.00529761 | Rate = 0.001000\n",
      "Epoch 13 | Train loss = 0.00517146 | Val loss =  0.00530017 | Rate = 0.001000\n",
      "Epoch 14 | Train loss = 0.00516155 | Val loss =  0.00531074 | Rate = 0.001000\n",
      "Epoch 15 | Train loss = 0.00515875 | Val loss =  0.00530149 | Rate = 0.001000\n",
      "Epoch 16 | Train loss = 0.00515456 | Val loss =  0.00529837 | Rate = 0.001000\n",
      "Epoch 17 | Train loss = 0.00514958 | Val loss =  0.00529518 | Rate = 0.001000\n",
      "Epoch 18 | Train loss = 0.00514598 | Val loss =  0.00527710 | Rate = 0.001000\n",
      "Epoch 19 | Train loss = 0.00514554 | Val loss =  0.00529428 | Rate = 0.001000\n",
      "Epoch 20 | Train loss = 0.00514054 | Val loss =  0.00529238 | Rate = 0.001000\n",
      "HDA Precision: 0.974 +/- 0.002\n",
      "LDA Precision: 0.995 +/- 0.002\n",
      "HDA Recall: 0.995 +/- 0.002\n",
      "LDA Recall: 0.973 +/- 0.001\n",
      "Accuracy: 0.984 +/- 0.001\n"
     ]
    }
   ],
   "source": [
    "# Prepare datasets for AE-GMM.\n",
    "X, y = load_data(model=MODEL, feat='stein', states=['hda', 'lda'])\n",
    "hda_idx = np.argwhere(y == 0).reshape(-1)\n",
    "lda_idx = np.argwhere(y == 1).reshape(-1)\n",
    "\n",
    "# Get a train/test split.\n",
    "metrics = {\n",
    "    'hda_precisions': [],\n",
    "    'lda_precisions': [],\n",
    "    'hda_recalls': [],\n",
    "    'lda_recalls': [],\n",
    "    'accuracies': []\n",
    "}\n",
    "prob_lda = []\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "for idx, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    print(f'Evaluating fold {idx + 1} / 5.')\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    model = AutoencoderGMM(input_dim=X.shape[1], latent_dim=2, num_classes=2)\n",
    "    model.fit(X_train, y_train, max_epochs=20)\n",
    "    y_pred, probs = model.predict(X_test, prob=True)\n",
    "\n",
    "    # Save probabilities for true configurations for subsequent analysis.\n",
    "    lda_idx = np.argwhere(y_test == 1).reshape(-1) \n",
    "    hda_idx = np.argwhere(y_test == 0).reshape(-1) \n",
    "    lda_probs = probs[lda_idx, 1]\n",
    "    hda_probs = probs[hda_idx, 0]\n",
    "    probabilities['ae-gmm']['lda'].append(lda_probs)\n",
    "    probabilities['ae-gmm']['hda'].append(hda_probs)      \n",
    "    y_pred = np.argmax(probs, axis=1)\n",
    "\n",
    "    # Save performance metrics.\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    metrics['hda_precisions'].append(conf_mat[0,0] / (conf_mat[1,0] + conf_mat[0,0]))\n",
    "    metrics['lda_precisions'].append(conf_mat[1,1] / (conf_mat[0,1] + conf_mat[1,1]))\n",
    "    metrics['hda_recalls'].append(conf_mat[0,0] / (conf_mat[0,1] + conf_mat[0,0]))\n",
    "    metrics['lda_recalls'].append(conf_mat[1,1] / (conf_mat[1,0] + conf_mat[1,1]))\n",
    "    metrics['accuracies'].append((conf_mat[0,0] + conf_mat[1,1]) / np.sum(conf_mat, axis=(0,1)))\n",
    "\n",
    "# Report accuracy metrics.\n",
    "print(f'HDA Precision: {np.mean(metrics[\"hda_precisions\"]):.3f} +/- {np.std(metrics[\"hda_precisions\"]):.3f}')\n",
    "print(f'LDA Precision: {np.mean(metrics[\"lda_precisions\"]):.3f} +/- {np.std(metrics[\"lda_precisions\"]):.3f}')\n",
    "print(f'HDA Recall: {np.mean(metrics[\"hda_recalls\"]):.3f} +/- {np.std(metrics[\"hda_recalls\"]):.3f}')\n",
    "print(f'LDA Recall: {np.mean(metrics[\"lda_recalls\"]):.3f} +/- {np.std(metrics[\"lda_recalls\"]):.3f}')\n",
    "print(f'Accuracy: {np.mean(metrics[\"accuracies\"]):.3f} +/- {np.std(metrics[\"accuracies\"]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8459df10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train loss = 0.00554428 | Val loss =  0.00551096 | Rate = 0.001000\n",
      "Epoch 2 | Train loss = 0.00534806 | Val loss =  0.00547527 | Rate = 0.001000\n",
      "Epoch 3 | Train loss = 0.00532525 | Val loss =  0.00546505 | Rate = 0.001000\n",
      "Epoch 4 | Train loss = 0.00529850 | Val loss =  0.00542263 | Rate = 0.001000\n",
      "Epoch 5 | Train loss = 0.00526191 | Val loss =  0.00539122 | Rate = 0.001000\n",
      "Epoch 6 | Train loss = 0.00522549 | Val loss =  0.00536223 | Rate = 0.001000\n",
      "Epoch 7 | Train loss = 0.00519498 | Val loss =  0.00533496 | Rate = 0.001000\n",
      "Epoch 8 | Train loss = 0.00518352 | Val loss =  0.00533539 | Rate = 0.001000\n",
      "Epoch 9 | Train loss = 0.00517209 | Val loss =  0.00532105 | Rate = 0.001000\n",
      "Epoch 10 | Train loss = 0.00515943 | Val loss =  0.00528979 | Rate = 0.001000\n",
      "Epoch 11 | Train loss = 0.00515922 | Val loss =  0.00530972 | Rate = 0.001000\n",
      "Epoch 12 | Train loss = 0.00515565 | Val loss =  0.00530088 | Rate = 0.001000\n",
      "Epoch 13 | Train loss = 0.00514691 | Val loss =  0.00529541 | Rate = 0.001000\n",
      "Epoch 14 | Train loss = 0.00514277 | Val loss =  0.00529378 | Rate = 0.001000\n",
      "Epoch 15 | Train loss = 0.00514097 | Val loss =  0.00528657 | Rate = 0.001000\n",
      "Epoch 16 | Train loss = 0.00513860 | Val loss =  0.00528255 | Rate = 0.001000\n",
      "Epoch 17 | Train loss = 0.00513335 | Val loss =  0.00528045 | Rate = 0.001000\n",
      "Epoch 18 | Train loss = 0.00512840 | Val loss =  0.00528305 | Rate = 0.001000\n",
      "Epoch 19 | Train loss = 0.00512481 | Val loss =  0.00526801 | Rate = 0.001000\n",
      "Epoch 20 | Train loss = 0.00512213 | Val loss =  0.00527199 | Rate = 0.001000\n"
     ]
    }
   ],
   "source": [
    "# Retrain AE-GMM model on all HDA, LDA, and liquid configurations.\n",
    "model = AutoencoderGMM(input_dim=X.shape[1], latent_dim=2, num_classes=2)\n",
    "model.fit(X, y, max_epochs=20)\n",
    "\n",
    "# Evaluate trained AE-GMM when extrapolating to hexagonal ice structures.\n",
    "X_ice = np.load(f'../data/descriptors/neigh_16/{MODEL}_ice_stein.npy')\n",
    "y_pred, prob_ice = model.predict(X_ice, prob=True)\n",
    "ice_probabilities['ae-gmm']['hda'] = prob_ice[:,0]\n",
    "ice_probabilities['ae-gmm']['lda'] = prob_ice[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2eaee235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1 / 5.\n",
      "Evaluating fold 2 / 5.\n",
      "Evaluating fold 3 / 5.\n",
      "Evaluating fold 4 / 5.\n",
      "Evaluating fold 5 / 5.\n",
      "HDA Precision: 0.986 +/- 0.002\n",
      "LDA Precision: 0.987 +/- 0.003\n",
      "HDA Recall: 0.987 +/- 0.003\n",
      "LDA Recall: 0.986 +/- 0.002\n",
      "Accuracy: 0.987 +/- 0.001\n"
     ]
    }
   ],
   "source": [
    "# Prepare training set for our model.\n",
    "MODEL = 'mbpol'\n",
    "X, y = load_data(model=MODEL, feat='all')\n",
    "hda_idx = np.argwhere(y == 0).reshape(-1)\n",
    "lda_idx = np.argwhere(y == 1).reshape(-1)\n",
    "\n",
    "# Assess classification accuracy for our model.\n",
    "metrics = {\n",
    "    'hda_precisions': [],\n",
    "    'lda_precisions': [],\n",
    "    'hda_recalls': [],\n",
    "    'lda_recalls': [],\n",
    "    'accuracies': []\n",
    "}\n",
    "prob_lda = []\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "for idx, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    print(f'Evaluating fold {idx + 1} / 5.')\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    model = ProbabilisticModel(\n",
    "        max_features=5, \n",
    "        include=0.98,\n",
    "        detect_outliers=False,\n",
    "        corr_cut=0.8,\n",
    "        use_features=[0]\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test, binary=True)   # Only consider HDA/LDA predictions.\n",
    "    log_probs = model.get_log_prob(X_test, binary=True) # Only consider HDA/LDA predictions.\n",
    "    probs = np.exp(log_probs)\n",
    "\n",
    "    # Save probabilities for true configurations for subsequent analysis.\n",
    "    lda_idx = np.argwhere(y_test == 1).reshape(-1) \n",
    "    hda_idx = np.argwhere(y_test == 0).reshape(-1) \n",
    "    lda_probs = probs[lda_idx, 1]\n",
    "    hda_probs = probs[hda_idx, 0]\n",
    "    probabilities['ours']['lda'].append(lda_probs)\n",
    "    probabilities['ours']['hda'].append(hda_probs)\n",
    "    \n",
    "    # Save performance metrics.\n",
    "    valid_idx = np.argwhere(y_pred != -1).reshape(-1)\n",
    "    conf_mat = confusion_matrix(y_test[valid_idx], y_pred[valid_idx])\n",
    "    metrics['hda_precisions'].append(conf_mat[0,0] / (conf_mat[1,0] + conf_mat[0,0]))\n",
    "    metrics['lda_precisions'].append(conf_mat[1,1] / (conf_mat[0,1] + conf_mat[1,1]))\n",
    "    metrics['hda_recalls'].append(conf_mat[0,0] / (conf_mat[0,1] + conf_mat[0,0]))\n",
    "    metrics['lda_recalls'].append(conf_mat[1,1] / (conf_mat[1,0] + conf_mat[1,1]))\n",
    "    metrics['accuracies'].append((conf_mat[0,0] + conf_mat[1,1]) / np.sum(conf_mat, axis=(0,1)))\n",
    "\n",
    "# Report accuracy metrics.\n",
    "print(f'HDA Precision: {np.mean(metrics[\"hda_precisions\"]):.3f} +/- {np.std(metrics[\"hda_precisions\"]):.3f}')\n",
    "print(f'LDA Precision: {np.mean(metrics[\"lda_precisions\"]):.3f} +/- {np.std(metrics[\"lda_precisions\"]):.3f}')\n",
    "print(f'HDA Recall: {np.mean(metrics[\"hda_recalls\"]):.3f} +/- {np.std(metrics[\"hda_recalls\"]):.3f}')\n",
    "print(f'LDA Recall: {np.mean(metrics[\"lda_recalls\"]):.3f} +/- {np.std(metrics[\"lda_recalls\"]):.3f}')\n",
    "print(f'Accuracy: {np.mean(metrics[\"accuracies\"]):.3f} +/- {np.std(metrics[\"accuracies\"]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a15d6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain our model on all HDA, LDA, and liquid configurations.\n",
    "model = ProbabilisticModel(\n",
    "    max_features=5, \n",
    "    include=0.98,\n",
    "    detect_outliers=False,\n",
    "    corr_cut=0.8,\n",
    "    # use_features=[0, 123, 104, 105, 122]\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "# Evaluate trained model when extrapolating to hexagonal ice structures.\n",
    "X_ice_acsf = np.load(f'../data/descriptors/neigh_16/{MODEL}_ice_acsf.npy')\n",
    "X_ice_stein = np.load(f'../data/descriptors/neigh_16/{MODEL}_ice_stein.npy')\n",
    "X_ice = np.hstack((X_ice_acsf, X_ice_stein))\n",
    "log_prob_ice = model.get_log_prob(X_ice, binary=True)\n",
    "prob_ice = np.exp(log_prob_ice)\n",
    "ice_probabilities['ours']['hda'] = prob_ice[:,0]\n",
    "ice_probabilities['ours']['lda'] = prob_ice[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91d68886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate predictions across folds.\n",
    "for model in probabilities.keys():\n",
    "    for state in probabilities[model].keys():\n",
    "        if len(probabilities[model][state]) > 0:\n",
    "            probabilities[model][state] = np.hstack((probabilities[model][state]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e880398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x350 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'Helvetica Neue'\n",
    "plt.rcParams['axes.linewidth'] = 1.2\n",
    "\n",
    "COLORS = ['#FF5A5F', \"#3188DA\"]\n",
    "STATE = 'lda'\n",
    "X_LABEL = 'Log ' + r'$P_{\\text{LDA}}$'\n",
    "\n",
    "fig, axs = plt.subplots(2,2,figsize=(3.5,3.5))\n",
    "\n",
    "# Plot results for BOO-NN.\n",
    "state_probs = probabilities['boo-nn'][STATE]\n",
    "ice_probs = ice_probabilities['boo-nn'][STATE]\n",
    "state_probs = state_probs + 1e-30\n",
    "ice_probs = ice_probs + 1e-30\n",
    "state_log_probs = np.log(state_probs)\n",
    "ice_log_probs = np.log(ice_probs)\n",
    "\n",
    "# For better smoothing of the KDE.\n",
    "state_log_probs_plot = state_log_probs[np.argwhere(state_log_probs > -0.1).reshape(-1)]\n",
    "ice_log_probs_plot = ice_log_probs[np.argwhere(ice_log_probs > -0.1).reshape(-1)]\n",
    "\n",
    "x = np.linspace(\n",
    "    min(np.min(state_log_probs_plot), np.min(ice_log_probs_plot)), \n",
    "    max(np.max(state_log_probs_plot), np.max(ice_log_probs_plot)), \n",
    "    200\n",
    ")\n",
    "lda_kde = gaussian_kde(state_log_probs_plot)\n",
    "y_lda = lda_kde(x)\n",
    "y_lda /= y_lda.max()\n",
    "ice_kde = gaussian_kde(ice_log_probs_plot)\n",
    "y_ice = ice_kde(x)\n",
    "y_ice /= y_ice.max()\n",
    "axs[0,0].plot(x, y_lda, color=COLORS[1], linewidth=0.9)\n",
    "axs[0,0].fill_between(x, y_lda, alpha=0.3, color=COLORS[1])\n",
    "axs[0,0].plot(x, y_ice, color=COLORS[0], linewidth=0.9)\n",
    "axs[0,0].fill_between(x, y_ice, alpha=0.3, color=COLORS[0])\n",
    "if STATE == 'lda':\n",
    "    axs[0,0].set_xlim(xmin=-0.05, xmax=0.0)\n",
    "    axs[0,0].set_xticks(ticks=[-0.05, -0.025, 0.0])\n",
    "else:\n",
    "    axs[0,0].set_xlim(xmin=-8.0, xmax=0.0)\n",
    "axs[0,0].set_ylim(ymin=0.0, ymax=1.05)\n",
    "axs[0,0].set_xlabel(X_LABEL)\n",
    "axs[0,0].set_ylabel('Density*')\n",
    "axs[0,0].set_yticks(ticks=[0.0, 0.5, 1.0])\n",
    "axs[0,0].tick_params(axis='both', width=1.2, length=3.0)\n",
    "axs[0,0].spines[['top', 'right']].set_visible(False)\n",
    "axs[0,0].set_title('BOO-NN')\n",
    "\n",
    "# Plot results for PointNet.\n",
    "state_probs = probabilities['pointnet'][STATE]\n",
    "ice_probs = ice_probabilities['pointnet'][STATE]\n",
    "state_probs = state_probs + 1e-30\n",
    "ice_probs = ice_probs + 1e-30\n",
    "state_log_probs = np.log(state_probs)\n",
    "ice_log_probs = np.log(ice_probs)\n",
    "\n",
    "# For better smoothing of the KDE.\n",
    "state_log_probs_plot = state_log_probs[np.argwhere(state_log_probs > -0.5).reshape(-1)]\n",
    "ice_log_probs_plot = ice_log_probs[np.argwhere(ice_log_probs > -0.5).reshape(-1)]\n",
    "\n",
    "x = np.linspace(\n",
    "    min(np.min(state_log_probs_plot), np.min(ice_log_probs_plot)), \n",
    "    max(np.max(state_log_probs_plot), np.max(ice_log_probs_plot)), \n",
    "    200\n",
    ")\n",
    "lda_kde = gaussian_kde(state_log_probs)\n",
    "y_lda = lda_kde(x)\n",
    "y_lda /= y_lda.max()\n",
    "ice_kde = gaussian_kde(ice_log_probs)\n",
    "y_ice = ice_kde(x)\n",
    "y_ice /= y_ice.max()\n",
    "axs[0,1].plot(x, y_lda, color=COLORS[1], linewidth=0.9)\n",
    "axs[0,1].fill_between(x, y_lda, alpha=0.3, color=COLORS[1])\n",
    "axs[0,1].plot(x, y_ice, color=COLORS[0], linewidth=0.9)\n",
    "axs[0,1].fill_between(x, y_ice, alpha=0.3, color=COLORS[0])\n",
    "if STATE == 'lda':\n",
    "    axs[0,1].set_xlim(xmin=-0.5, xmax=0.05)\n",
    "    axs[0,1].set_xticks(ticks=[-0.5, -0.25, 0.0])\n",
    "else:\n",
    "    axs[0,1].set_xlim(xmin=-15.0, xmax=0.0)\n",
    "axs[0,1].set_ylim(ymin=0.0, ymax=1.05)\n",
    "axs[0,1].set_xlabel(X_LABEL)\n",
    "axs[0,1].set_ylabel('Density*')\n",
    "axs[0,1].set_yticks(ticks=[0.0, 0.5, 1.0])\n",
    "axs[0,1].tick_params(axis='both', width=1.2, length=3.0)\n",
    "axs[0,1].spines[['top', 'right']].set_visible(False)\n",
    "axs[0,1].set_title('PointNet')\n",
    "\n",
    "# Plot results for AE-GMM.\n",
    "state_probs = probabilities['ae-gmm'][STATE]\n",
    "ice_probs = ice_probabilities['ae-gmm'][STATE]\n",
    "state_probs = state_probs + 1e-30\n",
    "ice_probs = ice_probs + 1e-30\n",
    "state_log_probs = np.log(state_probs)\n",
    "ice_log_probs = np.log(ice_probs)\n",
    "x = np.linspace(\n",
    "    min(np.min(state_log_probs), np.min(ice_log_probs)), \n",
    "    max(np.max(state_log_probs), np.max(ice_log_probs)), \n",
    "    2000\n",
    ")\n",
    "lda_kde = gaussian_kde(state_log_probs)\n",
    "y_lda = lda_kde(x)\n",
    "y_lda /= y_lda.max() \n",
    "axs[1,0].plot(x, y_lda, color=COLORS[1], linewidth=0.9)\n",
    "axs[1,0].fill_between(x, y_lda, alpha=0.3, color=COLORS[1])\n",
    "\n",
    "if STATE == 'lda':\n",
    "    ice_kde = gaussian_kde(ice_log_probs)\n",
    "    y_ice = ice_kde(x)\n",
    "    y_ice /= y_ice.max()\n",
    "    axs[1,0].plot(x, y_ice, color=COLORS[0], linewidth=0.9)\n",
    "    axs[1,0].fill_between(x, y_ice, alpha=0.3, color=COLORS[0])\n",
    "    axs[1,0].set_xticks(ticks=[-80, -40, 0.0])\n",
    "    axs[1,0].set_xlim(xmin=-80, xmax=0.00)\n",
    "else:\n",
    "    x_mean = np.mean(ice_log_probs)\n",
    "    axs[1,0].plot([x_mean, x_mean], [0.0, 1.0], color=COLORS[0], linewidth=0.9)\n",
    "    axs[1,0].set_xlim(xmin=-75, xmax=0.0)\n",
    "\n",
    "axs[1,0].set_ylim(ymin=0.0, ymax=1.05)\n",
    "axs[1,0].set_xlabel(X_LABEL)\n",
    "axs[1,0].set_ylabel('Density*')\n",
    "axs[1,0].set_yticks(ticks=[0.0, 0.5, 1.0])\n",
    "axs[1,0].tick_params(axis='both', width=1.2, length=3.0)\n",
    "axs[1,0].spines[['top', 'right']].set_visible(False)\n",
    "axs[1,0].set_title('AE-GMM')\n",
    "\n",
    "# Plot results for our work.\n",
    "state_probs = probabilities['ours'][STATE]\n",
    "ice_probs = ice_probabilities['ours'][STATE]\n",
    "state_probs = state_probs + 1e-30\n",
    "ice_probs = ice_probs + 1e-30\n",
    "state_log_probs = np.log(state_probs)\n",
    "ice_log_probs = np.log(ice_probs)\n",
    "\n",
    "x = np.linspace(\n",
    "    min(np.min(state_log_probs), np.min(ice_log_probs)), \n",
    "    max(np.max(state_log_probs), np.max(ice_log_probs)), \n",
    "    2000\n",
    ")\n",
    "lda_kde = gaussian_kde(state_log_probs)\n",
    "y_lda = lda_kde(x)\n",
    "y_lda /= y_lda.max()\n",
    "axs[1,1].plot(x, y_lda, color=COLORS[1], linewidth=0.9)\n",
    "axs[1,1].fill_between(x, y_lda, alpha=0.3, color=COLORS[1])\n",
    "if len(np.unique(ice_log_probs)) == 1:\n",
    "    unique_value = np.unique(ice_log_probs)[0]\n",
    "    axs[1,1].plot([unique_value, unique_value], [0.0, 1.0], color=COLORS[0])\n",
    "else:\n",
    "    ice_kde = gaussian_kde(ice_log_probs)\n",
    "    y_ice = ice_kde(x)\n",
    "    y_ice /= y_ice.max()\n",
    "    axs[1,1].plot(x, y_ice, color=COLORS[0], linewidth=0.9)\n",
    "    axs[1,1].fill_between(x, y_ice, alpha=0.3, color=COLORS[0])\n",
    "axs[1,1].set_xlim(xmin=-80, xmax=0.0)\n",
    "axs[1,1].set_ylim(ymin=0.0, ymax=1.05)\n",
    "axs[1,1].set_xlabel(X_LABEL)\n",
    "axs[1,1].set_xticks(ticks=[-80, -40, 0])\n",
    "axs[1,1].set_ylabel('Density*')\n",
    "axs[1,1].set_yticks(ticks=[0.0, 0.5, 1.0])\n",
    "axs[1,1].tick_params(axis='both', width=1.2, length=3.0)\n",
    "axs[1,1].spines[['top', 'right']].set_visible(False)\n",
    "axs[1,1].set_title('Ours')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'./figures/{STATE}_log_confidences_{MODEL}.svg', dpi=1000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reg-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}